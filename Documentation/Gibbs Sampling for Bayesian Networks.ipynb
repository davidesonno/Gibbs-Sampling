{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_Gibbs Sampling for Bayesian Networks_**\n",
    "\n",
    "_This notebook is used to motivate and explain in detail the code implemented. For further informations check `Davide_Sonno_Gibbs_sampling.pdf` ([file](Davide_Sonno_Gibbs_sampling.pdf))_.\n",
    "\n",
    "_The whole code is also available as module (*MarkovChainMonteCarlo*) and it is used to produce examples (check_ `MarkovChainMonteCarlo.examples`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Motivations**  \n",
    "Given the non polynomial nature of the exact inference, the complexity can rapidly increase with the size of the bayesan networks.  \n",
    "To be able to approximate the true distribution we can use Monte Carlo methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chains\n",
    "\n",
    "The key property for this approximation comes from the Markov chains, a random process generating a sequence of states from an initial states, in wich the next states only depends on the last state reached.  \n",
    "\n",
    "Whenever the algorithm used generates a chain with certain properties, such as visiting all the possible states without getting trapped in loops, we are sure that the amount of time spent in each state corresponds to the probability of that state.  \n",
    "\n",
    "The other property is called _detailed balance_ and expresses that the flow of probabilities between the states are balanced. If this condition is satisfied that Markov chain can be used to sample the desired probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python implementation**\n",
    "\n",
    "The following sections will show and motivate the code used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Approximate Inference**\n",
    "\n",
    "This class is a converging point for all the classes of algorithms that compute approximate inference. As for today the only method implemented is **Gibbs Sampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs sampling\n",
    "\n",
    "**_GibbsSampling_** object:\n",
    "    instantiates `self` using a BayesianNetwork and stores a copy of the *net* and of the CPDs for all the variables. The possible Markov Blankets are also pre-computed given that the net is static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GibbsSampling:\n",
    "    def __init__(self, model):\n",
    "        from pgmpy.models import BayesianNetwork\n",
    "        if not isinstance(model, BayesianNetwork):\n",
    "            raise ValueError(\"The model is not a pgmpy Bayesian Network\")\n",
    "        model.check_model()\n",
    "        self.model = model\n",
    "        self.cpds = model.cpds\n",
    "        self.variable_values = {\n",
    "            cpd.variable: cpd.state_names[cpd.variable] for cpd in self.cpds}\n",
    "        self.blankets = {\n",
    "            var: self.model.get_markov_blanket(var) \n",
    "            for var in self.variable_values.keys()\n",
    "            }\n",
    "    \n",
    "    # def query([...]): ...\n",
    "    # def check_evidence([...]): ...\n",
    "    # def check_variables([...]): ...\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *query* method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`query`:\n",
    "    Execute the approximate inference using the Gibbs Algorithm.\n",
    "\n",
    "_Parameters_:\n",
    "- variables: *list*\n",
    "    variables for which you want to compute the probability\n",
    "- evidence: *dict*\n",
    "    (key, value) pair as {var: state_of_var_observed}\n",
    "    None if no evidence\n",
    "- N: *int*\n",
    "    number of samples to be drawn\n",
    "- rounding: *int*\n",
    "    number of digits to print\n",
    "- the remaining variables are unused; they are there for portability with `pgmpy` `query` methods\n",
    "\n",
    "The steps performed by the algorithm are, in detail:\n",
    "1) check the values of `variables` and `evidence`\n",
    "2) ensure that the order of the values in `variables` is the same as in `self.variable_values.keys()`\n",
    "3) initiate the starting state, using the evidence and randomly drawing the remaining values\n",
    "4) choose the order in wich draw the variables\n",
    "5) initiate a `StateCounter` object, holding the counts of the state for the  variables in the query\n",
    "6) for the number of iterations fixed, execute:\n",
    "    - take the next variable from the ordering\n",
    "    - compute it's probability given all the other variables (we only need variables in it's Markov blanket)\n",
    "    - sample from a uniform variable in [0,1]\n",
    "    - update the state counter with the new value of the variable\n",
    "7) return a `QueryResult` object, that will normalize and provide an easy print to read values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GibbsSampling:\n",
    "    def query(\n",
    "            self,\n",
    "            variables,\n",
    "            evidence=None,\n",
    "            virtual_evidence=None,          # unused\n",
    "            elimination_order=\"greedy\",     #\n",
    "            joint=True,                     #\n",
    "            show_progress=True,             #\n",
    "            N=100_000,\n",
    "            rounding=4\n",
    "    ):\n",
    "        from pgmpy.inference import VariableElimination\n",
    "        from inference.State import StateCounter\n",
    "        from query import QueryResult\n",
    "        from math import ceil\n",
    "        from random import uniform,choice\n",
    "        self.check_variables(variables)\n",
    "        if evidence is not None:\n",
    "            self.check_evidence(evidence)\n",
    "        else:\n",
    "            evidence = dict()\n",
    "        if N < 1:\n",
    "            raise ValueError(\n",
    "                \"Number of iterations has to be greater than zero\")\n",
    "\n",
    "        arrange_variables(self.variable_values, variables)\n",
    "\n",
    "        current_state = self.variable_values.copy()\n",
    "        for var in current_state.keys():\n",
    "            if var in evidence.keys():\n",
    "                current_state[var] = evidence[var]\n",
    "            else:\n",
    "                current_state[var] = choice(self.variable_values[var])\n",
    "\n",
    "        ordering = [var for var in self.variable_values.keys()\n",
    "                    if var not in evidence.keys()]\n",
    "\n",
    "        state_counter = StateCounter(self.variable_values, variables)\n",
    "\n",
    "        for _ in range(ceil(N/len(ordering))):\n",
    "            for var in ordering:\n",
    "                current_evidence = {ce: current_state[ce] for ce in self.blankets[var]}\n",
    "                query = VariableElimination(self.model).query(\n",
    "                    [var], current_evidence).values\n",
    "                next_value_index = read_distribution(query, uniform(0, 1))\n",
    "                current_state[var] = self.variable_values[var][next_value_index]\n",
    "                state_counter.update(current_state)\n",
    "\n",
    "        return QueryResult(state_counter, rounding)\n",
    "\n",
    "    def check_evidence(self, evidence):\n",
    "        for e in list(evidence.keys()):\n",
    "            if evidence[e] not in self.variable_values[e]:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid state for {e}; possible states: {self.variable_values[e]}\")\n",
    "\n",
    "    def check_variables(self, variables):\n",
    "        for var in variables:\n",
    "            if var not in list(self.variable_values.keys()):\n",
    "                raise ValueError(\n",
    "                    f\"The variable {var} is not part of the model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_distribution`:\n",
    "    Returns the index value associated with the given probability\n",
    "\n",
    "_Parameters_:\n",
    "- query: *numpy array*\n",
    "    nparray containing the distribution of a query\n",
    "- probability: *float*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_distribution(query, probability:float):\n",
    "    step = 0\n",
    "    for i in range(len(query)):\n",
    "        if probability <= query[i]+step:\n",
    "            return i\n",
    "        step += query[i]\n",
    "    raise Exception(\"Next state not found or probability greater than 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arrange_variables`:\n",
    "    Re-arranges `variables` in-place according to the order of the keys of the dict\n",
    "\n",
    "_Parameters_:\n",
    "- values: *dict*\n",
    "    dict containing the variables and their values\n",
    "- variables: *iterable*\n",
    "    variables to arrange accordingly to the dict keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_variables(values: dict, variables:iter):\n",
    "    aux = []\n",
    "    for v in list(values.keys()):\n",
    "        if v in variables:\n",
    "            aux.append(v)\n",
    "    variables.clear()\n",
    "    variables.extend(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **State Counter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_StateCounter_** object:\n",
    "    structure holding the dict of states with the respective counts. It also stores the possible value for each variable and the variables requested in the query. The keys of the dict are tuples containing the values of the variable of the state.\n",
    "\n",
    "**Methods:**\n",
    "\n",
    "`update`:\n",
    "    Updates the count of the states, given a new state\n",
    "\n",
    "_Parameters_:\n",
    "- next_state: *dict*\n",
    "    dict containing values for the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "class StateCounter:\n",
    "    def __init__(self, values: dict, variables: list):\n",
    "        self.variables = variables\n",
    "        self.values = values\n",
    "\n",
    "        aux = [values[var] for var in variables]\n",
    "        combinations = list(product(*aux))\n",
    "        self.counter = {}\n",
    "        for i in range(len(combinations)):\n",
    "            self.counter[combinations[i]] = 0\n",
    "\n",
    "    def update(self, next_state):\n",
    "        values = tuple(next_state[var] for var in self.variables)\n",
    "        self.counter[values] += 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Query Result**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_QueryResult_** object:\n",
    "    structure holding the normalized values of the counts and provides an easy to read way to print the resulting probability\n",
    "    \n",
    "_Parameters:_\n",
    "- counts: *StateCounter*\n",
    "    the object used to store the counts of the states\n",
    "- rounding: *int* \n",
    "    optional parameter to be able to print smaller probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryResult:\n",
    "    def __init__(self, counts: StateCounter,rounding:int):\n",
    "        self.variables = counts.variables\n",
    "        self.values = counts.values\n",
    "        self.counts = counts.counter\n",
    "\n",
    "        tot=sum(list(self.counts.values()))\n",
    "        for state in self.counts.keys():\n",
    "            self.counts[state]/=tot\n",
    "        self.rounding=rounding\n",
    "\n",
    "    def __str__(self):\n",
    "        # lets see how \"large\" the words to print will be\n",
    "        max_widths={}\n",
    "        for var in self.variables:\n",
    "            max_widths[var]=max(len(f\"{var}({v})\") for v in self.values[var])\n",
    "        vars_text=','.join(str(var) for var in self.variables)\n",
    "        query_text=f'phi({vars_text})'\n",
    "        max_widths['probability']=len(query_text)+2\n",
    "\n",
    "        # create the separator for the rows\n",
    "        row_line=''\n",
    "        for var in self.variables:\n",
    "            row_line+=f\"+{'-'*(max_widths[var]+2)}\"\n",
    "        row_line+=f\"+{'-'*(max_widths['probability']+2)}+\\n\"\n",
    "\n",
    "        # create the table header\n",
    "        header=''\n",
    "        for var in self.variables:\n",
    "            header+=f\"| {var:<{max_widths[var]}} \"\n",
    "        header+=f\"| {query_text:>{max_widths['probability']}} |\\n\"\n",
    "\n",
    "        # create the separator between the header and the probabilities\n",
    "        thick_row_line=''\n",
    "        for var in self.variables:\n",
    "            thick_row_line+=f\"+{'='*(max_widths[var]+2)}\"\n",
    "        thick_row_line+=f\"+{'='*(max_widths['probability']+2)}+\\n\"\n",
    "\n",
    "        table=''\n",
    "        for state in list(self.counts.keys()):\n",
    "            # create the states\n",
    "            values = [f\"{var}({probability})\".ljust(max_widths[var]) for var, probability in zip(self.variables, state)]\n",
    "            formatted_values = ' | '.join(values)\n",
    "            formatted_counts = f\"{self.counts[state]:.{self.rounding}f}\" \n",
    "            # create the row\n",
    "            formatted_row = f\"| {formatted_values} | {' ' * (max_widths['probability'] - len(formatted_counts))}{formatted_counts} |\"\n",
    "            table+=formatted_row+'\\n'+row_line\n",
    "\n",
    "        return row_line+header+thick_row_line+table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibbs Sampling:\n",
    "# +-------------+---------------+----------------------------+\n",
    "# | Burglary    | Earthquake    |   phi(Burglary,Earthquake) |\n",
    "# +=============+===============+============================+\n",
    "# | Burglary(0) | Earthquake(0) |                     0.0000 |\n",
    "# +-------------+---------------+----------------------------+\n",
    "# | Burglary(0) | Earthquake(1) |                     0.0001 |\n",
    "# +-------------+---------------+----------------------------+\n",
    "# | Burglary(1) | Earthquake(0) |                     0.0014 |\n",
    "# +-------------+---------------+----------------------------+\n",
    "# | Burglary(1) | Earthquake(1) |                     0.9985 |\n",
    "# +-------------+---------------+----------------------------+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
